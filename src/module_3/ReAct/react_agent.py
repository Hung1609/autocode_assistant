from typing import List, Dict, Any, Optional, Tuple
import json
import logging
import re
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_google_genai import ChatGoogleGenerativeAI
import os

class ReActAgent:
    def __init__(self, llm, tools: List[Any], project_root: str, max_iterations: int = 99):
        self.llm = llm
        self.tools = {tool.name: tool for tool in tools}
        self.project_root = project_root
        self.max_iterations = max_iterations
        self.state = {
            "design_data": {},
            "spec_data": {},
            "created_folders": [],
            "generated_files": [],
            "validation_result": None,
            "run_script_executed": False,
            "history": []
        }
        self.logger = logging.getLogger(__name__)
        
    def run(self, task: str) -> str:
        self.state["history"].append(f"Task: {task}")
        iteration = 0
        observation = None
        
        while iteration < self.max_iterations:
            iteration += 1
            self.logger.info(f"Iteration {iteration}/{self.max_iterations}")
            
            response = self._generate_thought_and_action(observation)
            if not response:
                self.logger.error("No response generated by the LLM. Stopping.")
                return "Failed to generate response."
            
            thought, action, action_input, is_paused, answer = self._parse_response(response)
            self.state["history"].append(f"Thought: {thought}")
            self.logger.info(f"Thought: {thought}")
            
            if answer:
                self.state["history"].append(f"Answer: {answer}")
                self.logger.info(f"Answer: {answer}")
                return answer
        
            if not is_paused:
                self.logger.warning("No PAUSE detected. Stopping to avoid infinite loop.")
                return "No PAUSE detected in response."
            
            if not action or action not in self.tools:
                observation = f"Error: Invalid action '{action}'. Available actions: {list(self.tools.keys())}"
                self.state["history"].append(f"Observation: {observation}")
                self.logger.error(observation)
                continue
            
            self.state["history"].append(f"Action: {action_input}\nPAUSE")
            self.logger.info(f"Action: {action}: {action_input}")
            
            try:
                self.logger.info(f"Executing action: {action} with input: {action_input}")
                action_input_dict = json.loads(action_input)
                observation = self.tools[action]._run(**action_input_dict)
                self.state["history"].append(f"Observation: {observation}")
                self.logger.info(f"Observation: {observation}")
                self._update_state(action, action_input_dict, observation)
                
            except Exception as e:
                observation = f"Error executing action '{action}': {str(e)}"
                self.state["history"].append(f"Observation: {observation}")
                self.logger.error(observation)
                
        self.logger.warning("Max iterations reached.")
        return "Max iterations reached without completing task."
    
    def _generate_thought_and_action(self, observation: Optional[str]) -> Optional[str]:
        prompt = self._build_prompt(observation)
        try:
            response = self.llm.invoke([
                SystemMessage(content=self._get_system_prompt()),
                HumanMessage(content=prompt)
            ])
            return response.content.strip()
        
        except Exception as e:
            self.logger.error(f"Error generating response: {e}")
            return None
        
    def _build_prompt(self, observation: Optional[str]) -> str:
        history = "\n".join(self.state["history"])
        tools_description = "\n".join([f"- {name}: {tool.description}" for name, tool in self.tools.items()])
        state_summary = {
            "design_data": json.dumps(self.state["design_data"], indent=2)[:500] + "...",
            "spec_data": json.dumps(self.state["spec_data"], indent=2)[:500] + "...",
            "created_folders": self.state["created_folders"],
            "generated_files": self.state["generated_files"],
            "validation_result": self.state["validation_result"],
            "run_script_executed": self.state["run_script_executed"]
        }
        prompt = f"""
        Current State:
        - Design Data: {state_summary["design_data"]}
        - Spec Data: {state_summary["spec_data"]}
        - Created Folders: {state_summary["created_folders"]}
        - Generated Files: {state_summary["generated_files"]}
        - Validation Result: {state_summary["validation_result"]}
        - Run Script Executed: {state_summary["run_script_executed"]}
        
        History:
        {history}
        
        {f"Observation: {observation}" if observation else ""}
        
        Available Actions:
        {tools_description}
        
        Task: {self.state["history"][0].replace("Task: ", "")}
        
        Instructions:
        1. Output in the following format:
            Thought: [Your reasoning about what to do next based on the current state and observation]
            Action: [One of {', '.join(self.tools.keys())}]: {{JSON input}}
            PAUSE
        2. If the task is complete, output:
            Thought: [Reasoning that the task is complete]
            Answer: [Final result]
        3. Always provide a clear Thought explaining your decision.
        4. Use JSON for Action Input to support complex parameters.
        5. If an observation indicates an error, reason about how to recover or proceed.
        """
        return prompt
    
    def _get_system_prompt(self) -> str:
        return """
        You are an expert software architect tasked with generating a complete application based on .design.json and .spec.json files. 
        Follow a step-by-step reasoning process in a loop of Thought, Action, PAUSE, Observation. 
        Always articulate your thoughts before taking actions, explaining why you are choosing a specific action based on the current state, history, and observation.
        Use the provided actions to perform tasks and observe their results to guide your next steps.
        Output actions with JSON inputs for complex parameters. When the task is complete, provide an Answer.
        """
    
    def _parse_response(self, response: str) -> Tuple[str, str, str, bool, Optional[str]]:
        thought = ""
        action = ""
        action_input = ""
        is_paused = False
        answer = None
        
        # Use regex to detect PAUSE and split response
        pause_match = re.search(r'\bPAUSE\b', response, re.MULTILINE)
        if pause_match:
            is_paused = True
            response_lines = response[:pause_match.start()].split("\n")
        else:
            response_lines = response.slit("\n")
            
        for line in response_lines:
            line = line.strip()
            if line.startswith("Thought:"):
                thought = line[len("Thought:"):].strip()
            elif line.startswith("Action:"):
                action_parts = line[len("Action:"):].strip().split(":", 1)
                if len(action_parts) == 2:
                    action, action_input = action_parts
                    action = action.strip()
                    action_input = action_input.strip()
            elif line.startswith("Answer:"):
                answer = line[len("Answer:"):].strip()
        
        return thought, action, action_input, is_paused, answer
    
    def _update_state(self, action: str, action_input: Dict, observation: str):
        if action == "read_design_file":
            try:
                self.state["design_data"] = json.loads(observation)
            except:
                pass
        elif action == "read_spec_file":
            try:
                self.state["spec_data"] = json.loads(observation)
            except:
                pass
        elif action == "project_structure":
            try:
                self.state["created_folders"].extend(
                    [line.split(": ")[1] for line in observation.split("\n") if line.startswith("Directory:")]
                )
            except:
                pass
        elif action == "file_generator":
            try:
                file_path = action_input["file_path"]
                self.state["generated_files"].append(file_path)
            except:
                pass
        elif action == "project_validator":
            self.state["validation_result"] = observation
        elif action == "execute_run_script":
            self.state["run_script_executed"] = "successfully" in observation.lower()